---
title: "ES, Spark로 데이터분석"
date: 2024-03-28 21:00:00 +0400
categories: study, data
tags: study, data
---
# ES데이터 spark로 분석하기
## 환경설치
```sh
$ brew install apache-spark
$ echo 'export PATH="/opt/homebrew/opt/curl/bin:$PATH"' >> ~/.zshrc

# For compilers to find curl you may need to set:
#  export LDFLAGS="-L/opt/homebrew/opt/curl/lib"
#  export CPPFLAGS="-I/opt/homebrew/opt/curl/include"

# For pkg-config to find curl you may need to set:
#  export PKG_CONFIG_PATH="/opt/homebrew/opt/curl/lib/pkgconfig

## 로컬테스트 용도 이므로, local 환경으로 실행한다.
$ pyspark
```
http://localhost:4040/jobs/ 접속 확인

## sh ES 연동
```sh
$ spark-shell \
    --packages="org.elasticsearch:elasticsearch-spark-20_2.11:6.6.2"
```
```scala
// ES 연결을 위한 parameter
val esConf = Map(
    "es.nodes" -> "localhost:9200" // es hostname 지정
)

// ES에서 data를 로딩하여 DataFrame으로 반환
val df = spark.read.format("org.elasticsearch.spark.sql").options(esConf).load("log-1")
```
## java ES 연동
```java
public static void main(String[] args) {
		SparkConf conf = new SparkConf()
			.setAppName("LoadEsTest")
			.setMaster("local[*]")
			.set("spark.es.nodes", DEV_END)
			.set("spark.es.port", "portNumber")
			.set("spark.es.net.http.auth.user", "userId")
			.set("spark.es.net.http.auth.pass", "passwd");

		JavaSparkContext jsc = new JavaSparkContext(conf);

		JavaPairRDD<String, String> esRDD =
			JavaEsSpark.esJsonRDD(jsc, "indexName");

		esRDD.take(2).forEach(tuple -> {
			System.out.println("result " + tuple._1 + "\n" + tuple._2);

		});
	}
```
jdk 버전맞춘다고 시간을 좀 버렸는데, ES 버전에 맞춰서 설정을 해야한다.
ClassNotFound, 400 invalid request 등등 오류나면 일단 버전확인해보기
ES 7.5기준
- org.elasticsearch:elasticsearch-spark-20_2.11:7.5.0'
- JDK 1.8
- spark 2.4.0
- scala 2.11

### python 연동시 발생한 문제
- 버전 의존성이 맞지않음. 
- ES 7.5 > pyspark 2.4.5 & scala 2.11 > python3 > pyspark 3
- ES 버전업이 되어야 python 3, pyspark 3 이용 가능.

## cluster
- spring boot에서 여러 spark 서버에 job 분산 실행요청을 보내려면, 

## persistence data
- 로컬 스파크를 종료하면, 메모리에 올라와있던 dataframe도 날라간다. 이걸 유지시키려면 farqute 로 저장해야함
```java
// Write DataFrame to Parquet file
        dataFrame.write().parquet("path/to/destination");
```

# visualising
- python을 쓰면 참 좋겠지만, 버전 의존성으로 하지못함.
- java, jdk1.8 으로 할수있는 비주얼라이징 : jfree?
  - javafx는 jdk11 만 지원가능하게 바뀌었음.


--- 나중에보기
- python spark 조합으로 비주얼라이징 : https://learn.microsoft.com/ko-kr/fabric/data-science/python-guide/python-visualizations
- 